{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Report of Project 3: \"Implementation and evaluation of Otsu Thresholding\"**\n",
    "\n",
    "*presented by Elizaveta Chernova, Veronika Schuler, Laura Wächter, Hannah Winter*\n",
    "\n",
    "**Abstract**\n",
    "\n",
    "Otsu Thresholding is a valuable method for detecting the ideal threshold of an image. It is therefore used frequently in\n",
    "image segmentation for biological and medical purposes. Here we are going to use the implementation of this algorithm\n",
    "for segmentation of cell nuclei from the datasets N2DH-GOWT1 and N2DL-HeLa cells of the cell tracking challenge and the\n",
    "NIH3T3 images of Coelho and colleagues in their challenge of nuclear segmentation in microscope cell images.\n",
    "For pre-processing the images, we used histogram stretching for images with low resolution, a gaussian filter,\n",
    "and a median filter as well as two-level Otsu thresholding for excluding reflections in some images. The implemented\n",
    "Otsu algorithm used on the pre-processed images was then evaluated with the Dice score, the median surface distance\n",
    "function and the Hausdorff metric. We find that...\n",
    "\n",
    "**Table of contents**\n",
    "\n",
    "...\n",
    "\n",
    "**Introduction**\n",
    "\n",
    "In computer vision, image segmentation is applied to a variety of challenges. These challenges include detecting\n",
    "cell sizes and the number of cells in high-throughput cytometry or for cell tracking as well as segmentation of\n",
    "brain images.\n",
    "\n",
    "\n",
    "Challenges that need to be tackled in order to find the correct threshold for image segmentation are low contrast\n",
    "images, reflections and random noise that occur in the images. A starting point would be the preprocessing of the\n",
    "images before using the Otsu algorithm.\n",
    "\n",
    "\n",
    "The performance of the algorithm can be evaluated using the dice score as well as the median surface distance\n",
    "function and the Hausdorff metric, that compare the segmented image to the hand-segmented ground truth image.\n",
    "Furthermore, to give a purpose to the segmented images, we implemented a cell counting algorithm to determine the\n",
    "number of cells in an image. In addition to the performance measurement of the algorithm, we visualise the results\n",
    "with an overlay of the segmented image and the ground truth image.\n",
    "\n",
    "**Description of the datasets**\n",
    "\n",
    "*N2DH-GOWT1 cells*\n",
    "\n",
    "The dataset N2DH-GOWT1 of the cell tracking challenge (Bártová et al., 2011) contains images of GFP-GOWT1 mouse\n",
    "embryonic stem cells that have been derived with time-lapse confocal microscopy with a Leica TCS SP5 microscope.\n",
    "The varying brightness of the cells makes it hard to distinguish all the cells from the background.\n",
    "\n",
    "*N2HL-HeLa cells*\n",
    "\n",
    "The dataset N2DL-HeLa of the cell tracking challenge (Neumann et al., 2010) contains images of human epithelial cells\n",
    "of cervical cancer. Those images have been derived with an Olympus IX81 microscope used for live imaging of\n",
    "fluorescently labelled chromosomes. The challenge in these images is the variety of brightness of the cells.\n",
    "\n",
    "*NIH3T3 cells*\n",
    "\n",
    "The dataset NIH3T3 (Coelho et al., 2009) contains images of several mouse embryonic fibroblast cells. These images\n",
    "have also been derived with fluorescence microscopy images and the difficulty in segmenting these images mainly\n",
    "lies in the bright light spots, probably from the used microscope, that makes it difficult for the algorithm to choose\n",
    "a threshold between the brightness of the cells and the background and not between the brightness of light spots\n",
    "and the cells.\n",
    "\n",
    "\n",
    "**Import of modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.io import imshow\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.filters import threshold_otsu\n",
    "from nuclei_segmentation import pathlist\n",
    "from nuclei_segmentation import otsu\n",
    "from nuclei_segmentation import evaluation\n",
    "from nuclei_segmentation import visualisation\n",
    "import pathlib as pl\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Loading images, Preprocessing, Otsu, Evaluation of usage on datasets, Discussion**\n",
    "\n",
    "In order to receive nicely segmented images, we try different preprocessing methods for each of our datasets before\n",
    "using the Otsu algorithm and then evaluating the result with the Dice Score, the median surface distance and the hausdorff\n",
    "metric.\n",
    "\n",
    "The possible combinations were using only one of the following: gauss filter, median filter or histogram stretching.\n",
    "Other possibilities were using the gaussian filter or the median filter combined with histogram stretching.\n",
    "\n",
    "\n",
    "**Preprocessing**\n",
    "\n",
    "*Gauss filter*\n",
    "\n",
    "The Gaussian filter is a filter mask that multiplies the values of the neighboring pixels with values according to the\n",
    "gaussian distribution displayed below and takes the mean of those and the central pixel. This function is used for\n",
    "smoothing out noise in the images.\n",
    "\n",
    "\\begin{align*}\n",
    "G_σ(x,y) = \\frac{1}{σ^2 2π} \\\\ e^\\frac {-(x^2 + y^2)}{2σ^2} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "σ = standard \\enspace deviation\n",
    "\\end{align*}\n",
    "\n",
    "*Median filter*\n",
    "\n",
    "The median filter is a useful tool to tackle salt-and-pepper noise in the images. It takes the median intensity of the\n",
    "central pixel and the surrounding pixels in the neigborhood by weighting each pixel the same.\n",
    "\n",
    "*Histogram stretching*\n",
    "To solve the problem of low contrast images, we decided to use histogram stretching.\n",
    "To do that, the minimum and the maximum intensity values of the original image are taken and remapped to 0 or 1\n",
    "respectively. All the values in-between are recalculated based on a linear function.\n",
    "\n",
    "\\begin{align*}\n",
    "P_{out} = (P_{in} - c) \\frac{(b-a)}{(d-c)} \\\\ + \\enspace a\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "a \\enspace = \\enspace 0\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "b \\enspace = \\enspace 255\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "c \\enspace = \\enspace lowest \\enspace pixel \\enspace intensity \\enspace in\\enspace  the \\enspace image\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "d \\enspace = \\enspace highest \\enspace pixel \\enspace  intensity \\enspace in \\enspace the \\enspace  image\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "\n",
    "**Otsu's Thresholding**\n",
    "\n",
    "The next step after preprocessing our pictures is to implement our image segmentation algortihm with help of Otsu's\n",
    "thresholding.\n",
    "The Otsu algorithm is utilized to select the perfect threshold if the distribution is not bimodal by testing all possible\n",
    "threshold values k.\n",
    "The algorithm returns a single intensity threshold that separates all pixels into two classes – foreground and\n",
    "background. For the algorithm, only the gray value histogram of the image is needed.\n",
    "\n",
    "By using the mean intensity value (µ) as well as the probability of class occurrence of each class, the algorithm\n",
    "computes the in-between-class-variance for all of the possible threshold values k by searching for the value k\n",
    "that maximizes the between-class-variance. This value will be our optimal threshold.\n",
    "\n",
    "\n",
    "Between-class-variance:\n",
    "\n",
    "\\begin{align*}\n",
    "    σ_B = ω_0ω_1(µ_1 - µ_0)^2\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "σ = standard deviation\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "    ω_{0,1} = probability \\enspace of \\enspace class \\enspace occurrence\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "    µ_{0,1} = mean \\enspace intensity \\enspace values\n",
    "\\end{align*}\n",
    "\n",
    "Finally, we assign the intensity value 0 to all pixels having a lower or equal value than the computed optimal threshold\n",
    "value. Likewise, we assign the intensity value 255 to all pixels having a higher intensity value than the computed\n",
    "threshold.\n",
    "\n",
    "\\begin{align*}\n",
    "     g_{clip} (x,y)=\\left\\{\\begin{array}{ll}0 & if & g(x,y) <= k  \\\\\n",
    "     255 & if & g(x,y) > k\\end{array}\\right. .\n",
    "\\end{align*}\n",
    "\n",
    "Now we have received our binary image.\n",
    "\n",
    "*Two-level Otsu*\n",
    "\n",
    "Two-level Otsu basically works like the normal Otsu's algorithm, but instead of computing only one threshold,\n",
    "it gives out two thresholds that separate the pixels into two classes. This method is very useful to separate light\n",
    "reflections from the cells and don't count them as foreground.\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "σ_B^2 = ω_1(µ_1 - µ_T)^2 + ω_2(µ_1 - µ_T)^2\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "σ = standard deviation\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "    ω_{1,2} = probability \\enspace of \\enspace class \\enspace occurrence\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "    µ_{1,2} = mean \\enspace intensity \\enspace values\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "\n",
    "**Evaluation method**\n",
    "\n",
    "*Dice Score (DSC)*\n",
    "\n",
    "In this method we have a look at the overlapping area of the prediction and of the ground truth, compared to the total\n",
    "area of the prediction and the total are of the ground truth.\n",
    "Put in a formula:\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "    DSC = \\frac{2*|A ∩ B|}{|A| + |B|} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "A = GT\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "B = segmented \\enspace image\n",
    "\\end{align*}\n",
    "\n",
    "The value of the dice score measures how successful our cell nuclei segmentation was.The best score you can obtain is\n",
    "1 and the worst is 0.\n",
    "\n",
    "*Mean Surface Distance (MSD)*\n",
    "\n",
    "This method also evaluates how well our image segmentation, with the help of Otsu's thresholding, was performed on the\n",
    "given images.\n",
    "Thereby it measures the distance of the border of the segmented cell nuclei to the border of the ground truth nuclei.\n",
    "It computes the mean distance of all the calculated values.\n",
    "The formula used is depicted here:\n",
    "\n",
    "\\begin{align*}\n",
    "    d(p, S') = min ||p - p'||_2; \\enspace p' ∈ S'\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "    MSD = \\frac{1}{n_s + n_s'}  \\\\ (\\sum_{p=1}^{n_s} d(p,S') + \\sum_{p'=1}^{n_s'}  d(p',S))\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "    d = \\enspace distance\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "     S \\enspace and \\enspace S′= outer \\enspace surfaces\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "p = point \\enspace on \\enspace surface \\enspace S \\enspace and \\enspace the \\enspace surface \\enspace S′\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "*Hausdorff method*\n",
    "\n",
    "The Hausdorff method is very similar to MSD, the only difference is that it computes the maximum distance of all values.\n",
    "Thus, the formula must be:\n",
    "\n",
    "\\begin{align*}\n",
    "    HD = max[d(S,S'), \\enspace d(S',S)]\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "    d = \\enspace distance\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "     S \\enspace and \\enspace S′= outer \\enspace surfaces\n",
    "\\end{align*}\n",
    "\n",
    "*Cell counting*\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Results/new_values.json'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-3-d5256417b386>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"../Results/new_values.json\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"r\"\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mread_file\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m     \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mjson\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mread_file\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../Results/new_values.json'"
     ]
    }
   ],
   "source": [
    "with open(\"../Results/new_values.json\", \"r\") as read_file:\n",
    "    data = json.load(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dice_scores_GOWT1 = []\n",
    "msd_scores_GOWT1 = []\n",
    "\n",
    "for method in [\"No preprocessing\", \"Median filter\", \"Gaussian filter\", \"Histogram stretching\",\n",
    "               \"Median filter and histogram stretching\", \"Gauss filter and histogram stretching\"]:\n",
    "    dice_scores_GOWT1.append(data[method][\"N2DH-GOWT1\"][\"Dice Score\"])\n",
    "    msd_scores_GOWT1.append(data[method][\"N2DH-GOWT1\"][\"MSD\"])\n",
    "\n",
    "dice_scores = np.array(dice_scores_GOWT1)\n",
    "visualisation.comparison_preprocessing(dice_scores)\n",
    "\n",
    "msd_scores = np.array(msd_scores_GOWT1)\n",
    "visualisation.comparison_preprocessing(msd_scores, y_label='MSD Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Results:\n",
    "\n",
    "After applying all sorts of pre-processing methods, the highest dice score, with 81.7 %, was obtained when\n",
    "using the median filter and histogram stretching. Also here all sorts of pre-processing methods were used. Finally, the best median surface distance value was obtained\n",
    "when using only histogram stretching. The derived value is 2.282.\n",
    "\n",
    "Discussion:\n",
    "\n",
    "The images in this dataset were very low in contrast which made it hard to distinguish the all cell nuclei from\n",
    "the background.\n",
    "To solve this particular problem we decided to use histogram stretching. In order to do that, the minimum and\n",
    "the maximum intensity values of the original image are taken and remapped to 0 or 1. All the values in between are\n",
    "recalculated based on a linear function. After that, the median filter was implemented. The median takes the median\n",
    "intensity of the central pixel and the surrounding pixels in the neighborhood by weighing each pixel the same.\n",
    "As described above, histogram stretching increases the contrast of the cell nuclei images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Dataset 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dice_scores_HeLa = []\n",
    "msd_scores_HeLa = []\n",
    "\n",
    "for method in [\"No preprocessing\", \"Median filter\", \"Gaussian filter\", \"Histogram stretching\",\n",
    "               \"Median filter and histogram stretching\", \"Gauss filter and histogram stretching\"]:\n",
    "    dice_scores_HeLa.append(data[method][\"N2DL-HeLa\"][\"Dice Score\"])\n",
    "    msd_scores_HeLa.append(data[method][\"N2DL-HeLa\"][\"MSD\"])\n",
    "\n",
    "dice_scores = np.array(dice_scores_HeLa)\n",
    "visualisation.comparison_preprocessing(dice_scores)\n",
    "\n",
    "msd_scores = np.array(msd_scores_HeLa)\n",
    "visualisation.comparison_preprocessing(msd_scores, y_label='MSD Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Results\n",
    "\n",
    "We used all kinds of combinations of pre-processing functions on N2DL-HeLa cells. The dice score tells that a combination\n",
    "out of median filter and histogram stretching works best, with a mean value of 76 percent correctness. The mean value\n",
    "of all mean surface distance values is 5.527, which is quite low compared to the msd values of other datasets and\n",
    "confirms this pre-processing combination. Only the hausdorff value is 119,439 which is also good compared to other\n",
    "datasets but suggests a different pre-processing method to be the best choice for this kind of picture: the gaussian\n",
    "filter.\n",
    "\n",
    "Discussion\n",
    "\n",
    "The challenge in images of N2DL- HeLa cells is the strongly varying brightness. The median filter makes the image look\n",
    "smoother and the histogram stretching makes the contrast between foreground and background stronger. Therefore, the\n",
    "histogram of intensity levels has a deeper and sharper valley and it will be easier for Otsu’s algorithm to find the\n",
    "correct threshold. It does make sense to choose those pre-processing methods. There is only a correctness of 76 percent,\n",
    "because there are still cells with very low intensity values that are excluded as background and therefore deviate from\n",
    "the ground truth images.\n",
    "\n",
    "**Dataset 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dice_scores_NIH3T3 = []\n",
    "\n",
    "for method in [\"No preprocessing\", \"Median filter\", \"Gaussian filter\", \"Histogram stretching\",\n",
    "               \"Median filter and histogram stretching\", \"Gauss filter and histogram stretching\"]:\n",
    "    dice_scores_NIH3T3.append(data[method][\"NIH3T3\"][\"Dice Score\"])\n",
    "\n",
    "dice_scores = np.array(dice_scores_NIH3T3)\n",
    "visualisation.comparison_preprocessing(dice_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Conclusion**\n",
    "\n",
    "\n",
    "Hausdorff is not suitable since our segmentation methods are too imprecise and we therefore always receive very random\n",
    "values which are sometimes very high. Hausdorff takes the maximum surface-distance and it is therefore logical that\n",
    "the values turn out to be very high. However, we are of the opinion that Hausdorff is not really of use to us which is\n",
    "the reason why we are not applying this evaluation method.\n",
    "\n",
    "The values of the DSC and MSC differ greatly as both values explain how well the segmentation was performed in two\n",
    "different kind of ways. The DSC focuses on the overlap of the GT and the segmented image. The larger the area of\n",
    "overlap is, the higher the DSC will be.\n",
    "However, the MSD calculates the distance between the edges of the cells. The greater the distance,\n",
    "the greater the MSD, which implies that the segmentation is performed well. Vice versa, the smaller the MSD,\n",
    "the better the segmentation.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}